{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 and 5\n",
    "\n",
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from h5py import File\n",
    "\n",
    "from imagenet import ImagenetModel\n",
    "\n",
    "import json\n",
    "\n",
    "from scipy.misc import imshow\n",
    "\n",
    "from numpy import array, where, take, vstack, hstack\n",
    "\n",
    "from random import randint\n",
    "\n",
    "from theano.tensor import tensor4\n",
    "from theano import function\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_DATA_H5PY_FILE = './data/cocotalk.h5'\n",
    "IMG_DIR = './data/'\n",
    "JSON_COCOTALK = './json/cocotalk.json'\n",
    "JSON_COCO_RAW = './json/coco_raw.json'\n",
    "MATLAB_MODEL_FILE = './model/imagenet-vgg-verydeep-16.mat'\n",
    "\n",
    "WORD_PROBABILITY_TH = 0.01\n",
    "R = .299\n",
    "G = .587\n",
    "B = .144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imdl = ImagenetModel(MATLAB_MODEL_FILE)\n",
    "\n",
    "x = tensor4('x', dtype='float32')\n",
    "x_ = x\n",
    "for layer in imdl.layers:\n",
    "    x_ = layer.apply(x_)\n",
    "    \n",
    "the_func = function(inputs=[x], outputs=[x_], allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample\n",
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_file = File(IMAGE_DATA_H5PY_FILE, 'r')\n",
    "images = images_file['/images/']\n",
    "label_length = images_file['/label_length/']\n",
    "labels = images_file['/labels/']\n",
    "labels_start = images_file['/label_start_ix/']\n",
    "labels_end = images_file['/label_end_ix/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(JSON_COCOTALK) as f:\n",
    "    js = json.loads(f.read())\n",
    "    vocab = js['ix_to_word']\n",
    "with open(JSON_COCO_RAW) as f:\n",
    "    meta = json.loads(f.read())\n",
    "    captions = {}\n",
    "    pos2id_map = {}\n",
    "    i = 0\n",
    "    for e in js['images']:\n",
    "        pos2id_map[e['id']] = i\n",
    "        i+= 1\n",
    "    for e in meta:\n",
    "        captions[pos2id_map[e['id']]] = e['captions']\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspect the data or network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A woman riding a bike down a bike trail.',\n",
       " 'A woman looks behind her and smiles on a bicycle by water.',\n",
       " 'A woman is riding a bike along a pathway beside a lake.',\n",
       " 'a woman riding a bicycle on the sidewalk next to a body of water',\n",
       " 'A very pretty girl on a bike by the water.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_label(word_probs, entry_id, sep=' '):\n",
    "    p_vals = word_probs[0].flatten()\n",
    "    p_vals.sort()\n",
    "    ids = where(p_vals >= WORD_PROBABILITY_TH)\n",
    "    label_candidates = []\n",
    "    for id in ids[0]:\n",
    "        label_candidates.append(vocab[str(id)])\n",
    "    label_candidates.reverse()    \n",
    "    return sep.join(label_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entry_id = randint(0, images.shape[0]-1)\n",
    "result = the_func([images[entry_id]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pancake redone jump pepper queen michael positions snowboards telling wavy wave friendly windsurfer compact \n",
      "true labels: ['a cat rubbing its face against a bottle.c', 'A tabby cat rubs its face on a bottle of catnip.', 'A pretty cat sits next to a bottle of catnip.', 'Cat laying next to and sniffing a bottle of catnip', 'A man sitting on top of a tale next to a  bottle of catnip.']\n"
     ]
    }
   ],
   "source": [
    "label = get_label(result, entry_id)\n",
    "\n",
    "print(label, '\\ntrue labels:', captions[entry_id])\n",
    "imshow(images[entry_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# assignment 5\n",
    "## create training data\n",
    "\n",
    "We need to compute the 1000D-network output for each image. This output has to be set as input of the decoder k times, where k is the number of captions that exist for that particular image. E. g.:\n",
    "\n",
    "image_0 has 5 captions.\n",
    "\n",
    "1. compute x = f(image_0)\n",
    "2. align them:\n",
    "\n",
    "$decode\\bigg(\\begin{bmatrix}x\\\\x\\\\x\\\\x\\\\x\\end{bmatrix}\\bigg) = \\begin{bmatrix}repr(caption_1)\\\\repr(caption_2)\\\\repr(caption_3)\\\\repr(caption_4)\\\\repr(caption_5)\\end{bmatrix}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1000) (4, 16)\n"
     ]
    }
   ],
   "source": [
    "dec_x_rows = [] \n",
    "dec_y_rows = []\n",
    "TRAINING_LIMIT = 1\n",
    "for i in range(images.shape[0]):\n",
    "    if (i == TRAINING_LIMIT): break\n",
    "    a_1000_d = the_func([images[i]])[0]\n",
    "    for j in range(labels_start[i], labels_end[i]+1):\n",
    "        dec_x_rows.append(a_1000_d)\n",
    "        dec_y_rows.append(labels[j])\n",
    "\n",
    "dec_x = vstack(dec_x_rows)\n",
    "dec_y = vstack(dec_y_rows)\n",
    "print(dec_x.shape, dec_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MySimpleRecurrent(BaseRecurrent, Initializable):\n",
    "    @lazy(allocation=['dim'])\n",
    "    def __init__(self, dim, activation, **kwargs):\n",
    "        self.dim = dim\n",
    "        children = [activation]\n",
    "        kwargs.setdefault('children', []).extend(children)\n",
    "        super(MySimpleRecurrent, self).__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def W(self):\n",
    "        return self.parameters[0]\n",
    "\n",
    "    def get_dim(self, name):\n",
    "        if name == 'mask':\n",
    "            return 0\n",
    "        if name in (MySimpleRecurrent.apply.sequences +\n",
    "                    MySimpleRecurrent.apply.states):\n",
    "            return self.dim\n",
    "        return super(MySimpleRecurrent, self).get_dim(name)\n",
    "\n",
    "    def _allocate(self):\n",
    "        self.parameters.append(shared_floatx_nans((self.dim, self.dim), name=\"W\"))\n",
    "        add_role(self.parameters[0], WEIGHT)\n",
    "\n",
    "        # NB no parameters for initial state\n",
    "\n",
    "    def _initialize(self):\n",
    "        self.weights_init.initialize(self.W, self.rng)\n",
    "\n",
    "    @recurrent(sequences=['inputs', 'mask'], states=['states'],\n",
    "               outputs=['states'], contexts=['context'])\n",
    "    def apply(self, inputs, states, mask=None, **kwargs):\n",
    "        next_states = inputs + tensor.dot(states, self.W)\n",
    "        next_states = self.children[0].apply(next_states)\n",
    "        if mask:\n",
    "            next_states = (mask[:, None] * next_states +\n",
    "                           (1 - mask[:, None]) * states)\n",
    "        return next_states\n",
    "\n",
    "    @application(contexts=[\"context\"])\n",
    "    def initial_states(self, batch_size, *args, **kwargs):\n",
    "        init = kwargs[\"context\"]\n",
    "        return init.T\n",
    "\n",
    "    @initial_states.property('outputs')\n",
    "    def initial_states_outputs(self):\n",
    "        return self.apply.states\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
