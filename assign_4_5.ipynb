{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 and 5\n",
    "\n",
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from h5py import File\n",
    "\n",
    "from imagenet import ImagenetModel\n",
    "\n",
    "import json\n",
    "\n",
    "from scipy.misc import imshow\n",
    "\n",
    "from numpy import array, where, take\n",
    "\n",
    "from random import randint\n",
    "\n",
    "from theano.tensor import tensor4\n",
    "from theano import function\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_DATA_H5PY_FILE = './data/cocotalk.h5'\n",
    "IMG_DIR = './data/'\n",
    "JSON_COCOTALK = './json/cocotalk.json'\n",
    "JSON_COCO_RAW = './json/coco_raw.json'\n",
    "MATLAB_MODEL_FILE = './model/imagenet-vgg-verydeep-16.mat'\n",
    "\n",
    "WORD_PROBABILITY_TH = 0.01\n",
    "R = .299\n",
    "G = .587\n",
    "B = .144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imdl = ImagenetModel(MATLAB_MODEL_FILE)\n",
    "\n",
    "x = tensor4('x', dtype='float32')\n",
    "x_ = x\n",
    "for layer in imdl.layers:\n",
    "    x_ = layer.apply(x_)\n",
    "    \n",
    "the_func = function(inputs=[x], outputs=[x_], allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample\n",
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_file = File(IMAGE_DATA_H5PY_FILE, 'r')\n",
    "images = images_file['/images/']\n",
    "label_length = images_file['/label_length/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(JSON_COCOTALK) as f:\n",
    "    js = json.loads(f.read())\n",
    "    vocab = js['ix_to_word']\n",
    "with open(JSON_COCO_RAW) as f:\n",
    "    meta = json.loads(f.read())\n",
    "    captions = {}\n",
    "    pos2id_map = {}\n",
    "    i = 0\n",
    "    for e in js['images']:\n",
    "        pos2id_map[e['id']] = i\n",
    "        i+= 1\n",
    "    for e in meta:\n",
    "        captions[pos2id_map[e['id']]] = e['captions']\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspect the data or network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_label(word_probs, entry_id, sep=' '):\n",
    "    p_vals = word_probs[0].flatten()\n",
    "    p_vals.sort()\n",
    "    ids = where(p_vals >= WORD_PROBABILITY_TH)\n",
    "    label_candidates = []\n",
    "    for id in ids[0]:\n",
    "        label_candidates.append(vocab[str(id)])\n",
    "    label_candidates.reverse()    \n",
    "    return sep.join(label_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entry_id = randint(0, images.shape[0]-1)\n",
    "result = the_func([images[entry_id]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pancake redone jump pepper queen \n",
      "true labels: ['A man that is standing on a tennis court with a racquet.', 'a tennis player with a racket on the court ', 'A man holding a racquet on top of a tennis court.', 'An old man playing tennis on the tennis court.', 'The tennis player wearing a black cap is swinging a racket.']\n"
     ]
    }
   ],
   "source": [
    "label = get_label(result, image_id)\n",
    "\n",
    "print(label, '\\ntrue labels:', captions[entry_id])\n",
    "imshow(images[entry_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
